{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python37\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch import nn, Tensor\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "from Helpers import TST_model as tst\n",
    "from Helpers import inference as infer \n",
    "from Helpers import other_classes as other\n",
    "from Helpers import utils\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy\n",
    "import numpy\n",
    "import numpy\n",
    "#from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "#import dataset as ds\n",
    "#import transformer_timeseries as tst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read_file = pd.read_csv (r'C:\\Users\\admitos\\Desktop\\household_power_consumption.txt')\n",
    "#read_file.to_csv (r'C:\\Users\\admitos\\Desktop\\Ηousehold_power_consumption.csv', index=None)\n",
    "\n",
    "aal_file = pd.read_csv(r'C:\\Users\\admitos\\Desktop\\Visual Studio Notebooks\\Time Series Transformer\\AAL_data.csv')\n",
    "aap_file = pd.read_csv(r'C:\\Users\\admitos\\Desktop\\Visual Studio Notebooks\\Time Series Transformer\\AAP_data.csv')\n",
    "aapl_file = pd.read_csv(r'C:\\Users\\admitos\\Desktop\\Visual Studio Notebooks\\Time Series Transformer\\AAPL_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aal_data = aal_file.loc[:, aal_file.columns != 'Name']\n",
    "aap_data = aap_file.loc[:, aap_file.columns != 'Name']\n",
    "aapl_data = aapl_file.loc[:, aapl_file.columns != 'Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read_file.loc[0]\n",
    "#my_df = read_file['Date;Time;Global_active_power;Global_reactive_power;Voltage;Global_intensity;Sub_metering_1;Sub_metering_2;Sub_metering_3'].str.split(';', n=9, expand=True)\n",
    "#my_df.columns = ['Date', 'Time', 'Global_active_power', 'Global_reactive_power', 'Voltage', 'Global_intensity', 'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, input_size: int, dec_seq_len: int, batch_first: bool, out_seq_len: int=58, dim_val: int=512, n_encoder_layers: int=4, n_heads: int=8,\n",
    "        n_decoder_layers: int=4, dropout_encoder: float=0.2, dropout_decoder: float=0.2, dropout_pos_enc: float=0.1, dim_feedforward_encoder: int=2048,\n",
    "        dim_feedforward_decoder: int=2048, num_predicted_features: int=1): \n",
    "\n",
    "        x = 1\n",
    "\n",
    "#transformer_model = TimeSeriesTransformer(input_size, dec_seq_len, batch_first)\n",
    "# model = TimeSeriesTransformer(dim_val=dim_val, input_size=input_size, dec_seq_len=dec_seq_len, max_seq_len=max_seq_len, \n",
    "#        out_seq_len=output_sequence_length, n_decoder_layers=n_decoder_layers, n_encoder_layers=n_encoder_layers, n_heads=n_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-02-08</td>\n",
       "      <td>15.07</td>\n",
       "      <td>15.12</td>\n",
       "      <td>14.63</td>\n",
       "      <td>14.75</td>\n",
       "      <td>8407500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-02-11</td>\n",
       "      <td>14.89</td>\n",
       "      <td>15.01</td>\n",
       "      <td>14.26</td>\n",
       "      <td>14.46</td>\n",
       "      <td>8882000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-02-12</td>\n",
       "      <td>14.45</td>\n",
       "      <td>14.51</td>\n",
       "      <td>14.10</td>\n",
       "      <td>14.27</td>\n",
       "      <td>8126000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-02-13</td>\n",
       "      <td>14.30</td>\n",
       "      <td>14.94</td>\n",
       "      <td>14.25</td>\n",
       "      <td>14.66</td>\n",
       "      <td>10259500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-02-14</td>\n",
       "      <td>14.94</td>\n",
       "      <td>14.96</td>\n",
       "      <td>13.16</td>\n",
       "      <td>13.99</td>\n",
       "      <td>31879900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>54.00</td>\n",
       "      <td>54.64</td>\n",
       "      <td>53.59</td>\n",
       "      <td>53.88</td>\n",
       "      <td>3623078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>2018-02-02</td>\n",
       "      <td>53.49</td>\n",
       "      <td>53.99</td>\n",
       "      <td>52.03</td>\n",
       "      <td>52.10</td>\n",
       "      <td>5109361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>2018-02-05</td>\n",
       "      <td>51.99</td>\n",
       "      <td>52.39</td>\n",
       "      <td>49.75</td>\n",
       "      <td>49.76</td>\n",
       "      <td>6878284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>2018-02-06</td>\n",
       "      <td>49.32</td>\n",
       "      <td>51.50</td>\n",
       "      <td>48.79</td>\n",
       "      <td>51.18</td>\n",
       "      <td>6782480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>2018-02-07</td>\n",
       "      <td>50.91</td>\n",
       "      <td>51.98</td>\n",
       "      <td>50.89</td>\n",
       "      <td>51.40</td>\n",
       "      <td>4845831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1259 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date   open   high    low  close    volume\n",
       "0     2013-02-08  15.07  15.12  14.63  14.75   8407500\n",
       "1     2013-02-11  14.89  15.01  14.26  14.46   8882000\n",
       "2     2013-02-12  14.45  14.51  14.10  14.27   8126000\n",
       "3     2013-02-13  14.30  14.94  14.25  14.66  10259500\n",
       "4     2013-02-14  14.94  14.96  13.16  13.99  31879900\n",
       "...          ...    ...    ...    ...    ...       ...\n",
       "1254  2018-02-01  54.00  54.64  53.59  53.88   3623078\n",
       "1255  2018-02-02  53.49  53.99  52.03  52.10   5109361\n",
       "1256  2018-02-05  51.99  52.39  49.75  49.76   6878284\n",
       "1257  2018-02-06  49.32  51.50  48.79  51.18   6782480\n",
       "1258  2018-02-07  50.91  51.98  50.89  51.40   4845831\n",
       "\n",
       "[1259 rows x 6 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aal_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "test_size = 0.1\n",
    "validation_size = 0.1\n",
    "batch_size = 64\n",
    "target_col_name = [\"open\", \"close\"]\n",
    "timestamp_col = \"timestamp\"\n",
    "\n",
    "# Only use data from this date and onwards\n",
    "cutoff_date = datetime.datetime(2017, 1, 1) \n",
    "\n",
    "# Read data\n",
    "#data = utils.read_data(timestamp_col_name=timestamp_col)\n",
    "data = aal_data\n",
    "\n",
    "# Define input variables \n",
    "exogenous_vars = [] # should contain strings. Each string must correspond to a column name\n",
    "input_variables = [target_col_name] + exogenous_vars\n",
    "target_idx = 0 # index position of target in batched trg_y\n",
    "\n",
    "## Model parameters \n",
    "dim_val = 256 # This can be any value divisible by n_heads. 512 is used in the original transformer paper.\n",
    "n_heads = 4 # The number of attention heads (aka parallel attention layers). dim_val must be divisible by this number\n",
    "n_decoder_layers = 2 # Number of times the decoder layer is stacked in the decoder\n",
    "n_encoder_layers = 2 # Number of times the encoder layer is stacked in the encoder\n",
    "######## input_size = len(data.axes[1]) # The number of input variables. 1 if univariate forecasting.\n",
    "dec_seq_len = 21 # length of input given to decoder. Can have any integer value.\n",
    "enc_seq_len = 42 # length of input given to encoder. Can have any integer value.\n",
    "output_sequence_length = 10 # Length of the target sequence, i.e. how many time steps should your forecast cover\n",
    "max_seq_len = enc_seq_len # What's the longest sequence the model will encounter? Used to make the positional encoder\n",
    "window_size = enc_seq_len + output_sequence_length # used to slice data into sub-sequences\n",
    "step_size = 1 # Step size, i.e. how many time steps does the moving window move at each step\n",
    "in_features_encoder_linear_layer = 1024\n",
    "in_features_decoder_linear_layer = 1024\n",
    "batch_first = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples length:  1007\n",
      "Validation samples lenght:  126\n",
      "Test samples length:  126\n",
      "From get_src_trg: data size = torch.Size([1007, 2])\n",
      "src shape changed from: torch.Size([64, 42, 2]) to: torch.Size([42, 64, 2])\n",
      "trg shape changed from: torch.Size([64, 10, 1]) to: torch.Size([42, 64, 2])\n"
     ]
    }
   ],
   "source": [
    "# Remove test data from dataset\n",
    "train_val_data = data[:-(round(len(data)*test_size))]\n",
    "\n",
    "# Divide the training data to training and validation data\n",
    "training_data = train_val_data[:-(round(len(data)*validation_size))]\n",
    "print(\"Training samples length: \", len(training_data))\n",
    "validation_data = train_val_data[-(round(len(data)*validation_size)):]\n",
    "print(\"Validation samples lenght: \", len(validation_data))\n",
    "\n",
    "# Add test data seperately \n",
    "test_data = data[-(round(len(data)*test_size)):]\n",
    "print(\"Test samples length: \", len(test_data))\n",
    "\n",
    "# Make list of (start_idx, end_idx) pairs that are used to slice the time series sequence into chunkc. \n",
    "# Should be training data indices only\n",
    "training_indices = utils.get_indices_entire_sequence(data=training_data, window_size=window_size, step_size=step_size)\n",
    "validation_indices = utils.get_indices_entire_sequence(data=validation_data, window_size=window_size, step_size=step_size)\n",
    "\n",
    "# Making instance of custom dataset class\n",
    "training_dataset = other.TransformerDataset(data=torch.tensor(training_data[target_col_name].values).float(),\n",
    "    indices=training_indices, enc_seq_len=enc_seq_len, dec_seq_len=dec_seq_len, target_seq_len=output_sequence_length)\n",
    "\n",
    "#validation_dataset = other.TransformerDataset(data=torch.tensor(validation_data[target_col_name].values).float(),\n",
    "#    indices=validation_indices, enc_seq_len=enc_seq_len, dec_seq_len=dec_seq_len, target_seq_len=output_sequence_length)\n",
    "\n",
    "# Making a training dataloader\n",
    "training_dataloader = DataLoader(training_dataset, batch_size)\n",
    "i, batch = next(enumerate(training_dataloader))\n",
    "src, trg, trg_y = batch\n",
    "\n",
    "# Making a validation dataloader\n",
    "#validation_dataloader = DataLoader(validation_dataset, batch_size)\n",
    "#i, batch = next(enumerate(validation_dataloader))\n",
    "#src, _, trg_y = batch\n",
    "\n",
    "# Permute from shape [batch size, seq len, num features] to [seq len, batch size, num features]\n",
    "if batch_first == False:\n",
    "    shape_before = src.shape\n",
    "    src = src.permute(1,0,2)\n",
    "    print(\"src shape changed from: {} to: {}\".format(shape_before, src.shape))\n",
    "\n",
    "    shape_before = trg.shape\n",
    "    trg = trg.permute(1,0,2)\n",
    "    print(\"trg shape changed from: {} to: {}\".format(shape_before, src.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "0\n",
      "3\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for k,j in enumerate(validation_dataloader):\n",
    "    print(len(j))\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________Entering the transformer___________________________\n",
      "\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "transformer_model = tst.TimeSeriesTransformer(input_size=len(input_variables), dec_seq_len=enc_seq_len, batch_first=batch_first, \n",
    "                                            out_seq_len=output_sequence_length, dim_val=dim_val, n_encoder_layers=n_encoder_layers, \n",
    "                                            n_heads=n_heads, n_decoder_layers=n_decoder_layers, dim_feedforward_encoder=in_features_encoder_linear_layer, \n",
    "                                            dim_feedforward_decoder=in_features_decoder_linear_layer, num_predicted_features=1)\n",
    "\n",
    "# Make src mask for the encoder with size:\n",
    "# [batch_size*n_heads, output_sequence_length, enc_seq_len]\n",
    "src_mask = utils.generate_square_subsequent_mask(dim1=output_sequence_length, dim2=enc_seq_len)\n",
    "\n",
    "# Make tgt mask for the decoder with size:\n",
    "# [batch_size*n_heads, output_sequence_length, output_sequence_length]\n",
    "tgt_mask = utils.generate_square_subsequent_mask(dim1=output_sequence_length, dim2=output_sequence_length)\n",
    "\n",
    "# Perform one pass through the transformer\n",
    "print(\"________________________Entering the transformer___________________________\\n\")\n",
    "output = transformer_model(src=src, tgt=trg, src_mask=src_mask, tgt_mask=tgt_mask)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************Epoch: 0\n",
      "\n",
      "\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 57, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 57, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 57, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 57, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([57, 10])\n",
      "The size of the target_y is:  torch.Size([57, 10])\n",
      "********************Epoch: 1\n",
      "\n",
      "\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 57, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 57, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 57, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 57, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([57, 10])\n",
      "The size of the target_y is:  torch.Size([57, 10])\n",
      "********************Epoch: 2\n",
      "\n",
      "\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 57, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 57, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 57, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 57, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([57, 10])\n",
      "The size of the target_y is:  torch.Size([57, 10])\n",
      "********************Epoch: 3\n",
      "\n",
      "\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 57, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 57, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 57, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 57, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([57, 10])\n",
      "The size of the target_y is:  torch.Size([57, 10])\n",
      "********************Epoch: 4\n",
      "\n",
      "\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 57, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 57, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 57, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 57, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([57, 10])\n",
      "The size of the target_y is:  torch.Size([57, 10])\n",
      "********************Epoch: 5\n",
      "\n",
      "\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 57, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 57, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 57, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 57, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([57, 10])\n",
      "The size of the target_y is:  torch.Size([57, 10])\n",
      "********************Epoch: 6\n",
      "\n",
      "\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 57, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 57, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 57, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 57, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([57, 10])\n",
      "The size of the target_y is:  torch.Size([57, 10])\n",
      "********************Epoch: 7\n",
      "\n",
      "\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 57, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 57, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 57, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 57, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([57, 10])\n",
      "The size of the target_y is:  torch.Size([57, 10])\n",
      "********************Epoch: 8\n",
      "\n",
      "\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 57, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 57, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 57, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 57, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([57, 10])\n",
      "The size of the target_y is:  torch.Size([57, 10])\n",
      "********************Epoch: 9\n",
      "\n",
      "\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 57, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 57, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 57, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 57, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([57, 10])\n",
      "The size of the target_y is:  torch.Size([57, 10])\n",
      "********************Epoch: 10\n",
      "\n",
      "\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 57, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 57, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 57, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 57, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([57, 10])\n",
      "The size of the target_y is:  torch.Size([57, 10])\n",
      "********************Epoch: 11\n",
      "\n",
      "\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 57, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 57, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 57, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 57, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([57, 10])\n",
      "The size of the target_y is:  torch.Size([57, 10])\n",
      "********************Epoch: 12\n",
      "\n",
      "\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 57, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 57, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 57, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 57, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([57, 10])\n",
      "The size of the target_y is:  torch.Size([57, 10])\n",
      "********************Epoch: 13\n",
      "\n",
      "\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 57, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 57, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 57, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 57, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([57, 10])\n",
      "The size of the target_y is:  torch.Size([57, 10])\n",
      "********************Epoch: 14\n",
      "\n",
      "\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 57, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 57, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 57, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 57, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([57, 10])\n",
      "The size of the target_y is:  torch.Size([57, 10])\n",
      "********************Epoch: 15\n",
      "\n",
      "\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 57, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 57, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 57, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 57, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([57, 10])\n",
      "The size of the target_y is:  torch.Size([57, 10])\n",
      "********************Epoch: 16\n",
      "\n",
      "\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 57, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 57, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 57, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 57, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([57, 10])\n",
      "The size of the target_y is:  torch.Size([57, 10])\n",
      "********************Epoch: 17\n",
      "\n",
      "\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 57, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 57, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 57, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 57, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([57, 10])\n",
      "The size of the target_y is:  torch.Size([57, 10])\n",
      "********************Epoch: 18\n",
      "\n",
      "\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 57, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 57, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 57, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 57, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([57, 10])\n",
      "The size of the target_y is:  torch.Size([57, 10])\n",
      "********************Epoch: 19\n",
      "\n",
      "\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 64, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 64, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 64, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 64, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 64, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 64, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([64, 10])\n",
      "The size of the target_y is:  torch.Size([64, 10])\n",
      "================ Passing through new batch ===================\n",
      "From model.forward(): Size of src as given to forward(): torch.Size([42, 57, 1])\n",
      "From model.forward(): tgt size = torch.Size([10, 57, 1])\n",
      "------------------ Start the forward in the transformer----------------------- \n",
      "\n",
      "From model.forward(): Size of src after input layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after pos_enc layer: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of src after encoder: torch.Size([42, 57, 256])\n",
      "From model.forward(): Size of decoder_output after linear decoder layer: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output shape after decoder: torch.Size([10, 57, 256])\n",
      "From model.forward(): decoder_output size after linear_mapping = torch.Size([10, 57, 1])\n",
      "\n",
      "\n",
      "The size of the transformer output (i.e. prediction) is:  torch.Size([10, 57, 1])\n",
      "The size of the transformer output after squeeze and reshape is:  torch.Size([57, 10])\n",
      "The size of the target_y is:  torch.Size([57, 10])\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "forecast_window = output_sequence_length # supposing you're forecasting 48 hours ahead\n",
    "#########enc_seq_len = 168 # supposing you want the model to base its forecasts on the previous 7 days of data\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer_model.parameters())\n",
    "criterion = torch.nn.MSELoss()\n",
    "loss_list = []\n",
    "\n",
    "# Iterate over all epochs\n",
    "for epoch in range(epochs):\n",
    "    print(\"********************Epoch: {}\".format(epoch))\n",
    "    print(\"\\n\")\n",
    "    batch_loss = []\n",
    "    # Iterate over all (x,y) pairs in training dataloader\n",
    "    for i, (src, tgt, tgt_y) in enumerate(training_dataloader):\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        print(\"================ Passing through new batch ===================\")\n",
    "        optimizer.zero_grad()\n",
    "        if batch_first == False:\n",
    "            src = src.permute(1, 0, 2)\n",
    "            tgt = tgt.permute(1, 0, 2)\n",
    "\n",
    "        # Generate masks\n",
    "        src_mask = utils.generate_square_subsequent_mask(dim1=forecast_window, dim2=enc_seq_len)\n",
    "        tgt_mask = utils.generate_square_subsequent_mask(dim1=forecast_window, dim2=forecast_window)\n",
    "\n",
    "        # Make forecasts\n",
    "        prediction = transformer_model(src, tgt, src_mask, tgt_mask)\n",
    "\n",
    "        # Compute and backprop loss\n",
    "        print(\"\\n\")\n",
    "        print(\"The size of the transformer output (i.e. prediction) is: \", prediction.shape)\n",
    "        prediction = torch.squeeze(prediction,2)\n",
    "        prediction = torch.reshape(prediction,(prediction.shape[1], prediction.shape[0]))\n",
    "        print(\"The size of the transformer output after squeeze and reshape is: \", prediction.shape)\n",
    "        print(\"The size of the target_y is: \", tgt_y.shape)\n",
    "        loss = criterion(tgt_y, prediction)\n",
    "        batch_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "\n",
    "        # Take optimizer step\n",
    "        optimizer.step()\n",
    "    loss_list.append(np.mean(batch_loss))\n",
    "    continue\n",
    "\n",
    "    # Iterate over all (x,y) pairs in validation dataloader\n",
    "    transformer_model.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for i, (src, _, tgt_y) in enumerate(validation_dataloader):\n",
    "            prediction = infer.run_encoder_decoder_inference(model=transformer_model, src=src, forecast_window=forecast_window, batch_size=src.shape[1])\n",
    "\n",
    "            loss = criterion(tgt_y, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(len(loss_list))\n",
    "plt.plot(loss_list)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d49c3f6d6dd49f9272b571d9fad348ab55b8c6c3f691520d74ed0af1f69c3dd8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
